version: '3'

vars:
  WAREHOUSE_DIR: "~/tmp/iceberg/warehouse"
  SPARK_VERSION: "3.5.5"
  KAFKA_INSTALLATION_DIR: "~/kafka-dir"
  KAFKA_TOPIC: "mentor_cruise"

tasks:

  init-iceberg-setup:
    desc: Create local warehouse directory
    cmds:
      - mkdir -p {{.WAREHOUSE_DIR}}

  setup-venv:
    desc: Setup Python virtual environment
    cmds:
      - uv venv .venv

  install-python-dependencies:
    cmds:
      - bash -c "source .venv/bin/activate && uv pip install -r pyproject.toml"

  build-project-modules:
    desc: Build Python modules
    cmds:
      - bash -c "source .venv/bin/activate && python3.12 -m pip install -e ."

  setup-kafka:
    desc: Setup Kafka environment
    cmds:
      - mkdir -p {{.KAFKA_INSTALLATION_DIR}}
      - cd {{.KAFKA_INSTALLATION_DIR}} && curl -O https://dlcdn.apache.org/kafka/4.0.0/kafka_2.13-4.0.0.tgz
      - cd {{.KAFKA_INSTALLATION_DIR}} && tar -xzf kafka_2.13-4.0.0.tgz
      - cd {{.KAFKA_INSTALLATION_DIR}} && mv kafka_2.13-4.0.0 kafka

  setup-nessie-catalog:
    desc: Setup Nessie environment
    cmds:
      - docker run --rm -d --name nessie -p 19120:19120 ghcr.io/projectnessie/nessie:latest

  start-kafka-first-time:
    desc: Start Kafka service
    cmds:
      - |
        cd {{.KAFKA_INSTALLATION_DIR}}/kafka
        export KAFKA_CLUSTER_ID=$(bin/kafka-storage.sh random-uuid)
        rm -rf /tmp/kraft-combined-logs
        bin/kafka-storage.sh format --standalone -t $KAFKA_CLUSTER_ID -c config/server.properties
        bin/kafka-server-start.sh config/server.properties

  create-kafka-topic:
    desc: Create Kafka topic
    cmds:
      - cd {{.KAFKA_INSTALLATION_DIR}}/kafka && bin/kafka-topics.sh --create --topic {{.KAFKA_TOPIC}} --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1

  start-kafka-consumer:
    desc: Start Kafka consumer
    cmds:
      - cd {{.KAFKA_INSTALLATION_DIR}}/kafka && bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic {{.KAFKA_TOPIC}}

  stop-kafka:
    desc: Stop Kafka service
    cmds:
      - cd {{.KAFKA_INSTALLATION_DIR}}/kafka && bin/kafka-server-stop.sh

  start-kafka:
    desc: Start Kafka service
    cmds:
      - |
        cd {{.KAFKA_INSTALLATION_DIR}}/kafka

#        export KAFKA_CLUSTER_ID=$(bin/kafka-storage.sh random-uuid)
#        bin/kafka-storage.sh format --standalone -t $KAFKA_CLUSTER_ID -c config/server.properties
        bin/kafka-server-start.sh config/server.properties

  run-pyspark-data-processing:
    desc: Run data generation module
    cmds:
      - bash -c "source .venv/bin/activate && python -m streaming_data_pipeline.data_processing.src.main"

  run-random-data-generation:
    desc: Run data generation module
    cmds:
      - bash -c "source .venv/bin/activate && python -m streaming_data_pipeline.data_generation.src.main"

  run-pyspark-batch-job:
    desc: Run PySpark batch job
    cmds:
      - bash -c "source .venv/bin/activate && python -m batch_data_pipeline.src.main"